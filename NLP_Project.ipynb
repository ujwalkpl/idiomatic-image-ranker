{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39306cb-48c6-4457-a5e6-254217f2d83b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093593f0-44ca-40e1-9dea-59a4882208ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujwalkarippalichandran/Ujwal /Masters/Sem2/NLP/Project/NLP-Project/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from PIL import Image\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1552bef1-cec4-43b2-a6be-f5b3ead70e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ce9898-87b9-4498-92f7-58392b1bad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e834d849-7faa-465d-9da6-0882920ddc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "# def gloss_text(text):\n",
    "#     try:\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"deepseek/deepseek-r1-zero:free\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"You convert idiomatic or ambiguous English sentences into clear literal gloss sentences.\"},\n",
    "#                 {\"role\": \"user\", \"content\": f\"Gloss this sentence: {text}\"}\n",
    "#             ]\n",
    "#         )\n",
    "#         print(response)\n",
    "#         return response.choices[0].message.content.strip()\n",
    "#     except Exception as e:\n",
    "#         print(response)\n",
    "#         print(f\"Glossing failed: {e}\")\n",
    "#         return text  # fallback to original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cffb10-df9a-4a85-969d-c00ba2d21496",
   "metadata": {},
   "source": [
    "### API calls to DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee189d-4d4d-42e6-858f-437ec265477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def gloss_text(text, max_retries=3, retry_delay=2):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"deepseek/deepseek-r1-zero:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a language expert. Your task is to convert idiomatic or figurative language into literal explanations.\\n\"\n",
    "                    \"- If the sentence contains an idiom or figurative expression, rewrite it by replacing those parts with clear, literal meanings.\\n\"\n",
    "                    \"- If it doesn't, return the sentence unchanged.\\n\"\n",
    "                    \"DO NOT explain your reasoning or provide commentary. ONLY return the final rewritten sentence.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        \"reasoning\": {\n",
    "            \"effort\": \"low\",\n",
    "            \"exclude\": True \n",
    "        }\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "            result = response.json()\n",
    "            content = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            if content:\n",
    "                return content\n",
    "            else:\n",
    "                print(f\"Attempt {attempt}: Empty content received. Retrying...\")\n",
    "                time.sleep(retry_delay)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt}: Glossing failed due to error: {e}\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    print(\"Max retries reached. Returning original text.\")\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec785d10-8f53-4f66-9774-03bdaa4a65c7",
   "metadata": {},
   "source": [
    "### For glossing the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3a6a2ac-6300-4165-8f41-7b4cc21509c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_gloss(df):\n",
    "    gloss_cache = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"sentence\"] not in gloss_cache:\n",
    "            sentence = row[\"sentence\"]\n",
    "            #gloss = gloss_idiomatic_sentence(sentence)\n",
    "            gloss = gloss_text(sentence)\n",
    "            # Extract from \\boxed{...}\n",
    "            match = re.search(r\"\\\\boxed\\{(.+?)\\}\", gloss)\n",
    "            extracted = match.group(1).strip() if match else gloss.strip()\n",
    "            #print(extracted)\n",
    "            gloss_cache[sentence] = extracted if extracted != \"\" else sentence\n",
    "            print(f\"\\n Sentence: {sentence}\\n Gloss: {gloss_cache[sentence]}\\n\")\n",
    "    return gloss_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64677478-8e56-450d-bbf4-611ae8f36870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new one\n",
      "ChatCompletion(id='gen-1745806445-LfisyYGvUtLNSgajdaso', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='To solve for whether the sentence contains an idiom or figurative expression, let us first identify any part of the sentence that might be an idiom or a figurative expression. \\n\\nThe sentence given is:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s graveyard shift.\"\\n\\nThe part of the sentence that seems like a potential idiom or figurative expression is \"graveyard shift.\" \\n\\nThe term \"graveyard shift\" typically refers to a work shift that takes place during the late night to early morning hours, usually from midnight until 8 a.m. It is called a \"graveyard shift\" because it is a time when most people are asleep, which makes it a quiet and often less desirable shift to work. \\n\\nBased on this, \"graveyard shift\" is indeed an idiom or a figurative expression. To make the sentence clearer, we need to replace \"graveyard shift\" with a clear explanation of its meaning. \\n\\nThe sentence could be rewritten as:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late night to early morning shift.\"\\n\\nHowever, a more common and well-known part of the \"graveyard shift\" is that it usually refers to a shift that starts at midnight and goes until the early morning hours (often until 8 a.m.). Another common understanding is that a \"graveyard shift\" is a work shift that occurs during the \"dead of night,\" which makes it a less popular shift because it is a time when most people are asleep. \\n\\nHowever, the sentence already mentions a \"10 pm slot,\" so it seems that the \"graveyard shift\" should be a time slot that is later than 10 pm. Thus, a \"graveyard shift\" here likely means a very late night or overnight shift. \\n\\nHowever, a \"10 pm slot\" itself might be considered a part of the \"late night\" programming, so it might be a bit confusing here. However, a \"graveyard shift\" is usually even later than a \"10 pm slot.\" \\n\\nAnother part of the sentence mentions that he moved \"to his lower profile life as a DJ on Radio Norwich\\'s graveyard shift.\" This implies that the \"graveyard shift\" is a less prestigious or lower profile position compared to his previous \"10 pm slot.\" \\n\\nBased on this, a more specific and clear way to explain \"graveyard shift\" might be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s overnight shift (typically from midnight to early morning).\"\\n\\nHowever, a more concise and still clear way to make the sentence more explicit might be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s overnight shift.\"\\n\\nHowever, \"overnight shift\" might still be a bit vague. Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late night to early morning shift.\"\\n\\nHowever, \"overnight shift\" is a well-understood term that should suffice here. Thus, a well-reasoned and clear sentence could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s overnight shift.\"\\n\\nHowever, \"overnight shift\" might still be a bit of a \"term\" itself. Another way to make it even more explicit could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s shift that runs from late night until early morning.\"\\n\\nHowever, \"overnight shift\" is a well-known term that should make the sentence clear enough. Thus, a well-reasoned and clear sentence could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s overnight shift.\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s midnight to early morning shift.\"\\n\\nHowever, \"graveyard shift\" is a well-known term itself, so another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (often referred to as the graveyard shift, which typically runs from midnight until early morning).\"\\n\\nHowever, a more straightforward and less verbose way might be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his lower profile life as a DJ on Radio Norwich\\'s late-night shift (which typically runs from midnight until early morning).\"\\n\\nHowever, a more common and well-understood term for a \"graveyard shift\" is a \"midnight shift\" or \"overnight shift.\" Another way to make it more specific could be:\\n\"He moved from the 10 pm slot to his'), native_finish_reason='length')], created=1745806445, model='deepseek/deepseek-r1-zero:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=4096, prompt_tokens=98, total_tokens=4194, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gloss_text(\"Its raining cats and dogs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae13c30-0c1a-411d-864c-2306e691875c",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823179b8-8451-4eee-86c1-d335a2335e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train/subtask_a_train.tsv\", sep='\\t')\n",
    "dev_df = pd.read_csv(\"dev/subtask_a_dev.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"test/subtask_a_test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef44f26-5b4f-48e1-acf9-8fd370cf67e1",
   "metadata": {},
   "source": [
    "### The following code creates gloss sentences for train, dev, test using DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6eee6ffc-da33-4f21-83aa-0f3660432e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_1 = train_df[0:30]\n",
    "# train_df_2 = train_df[30:60]\n",
    "# train_df_3 = train_df[60:]\n",
    "\n",
    "# gloss_sentences_train_1 = preprocess_gloss(train_df_1)\n",
    "# gloss_sentences_train_2 = preprocess_gloss(train_df_2)\n",
    "# gloss_sentences_train_3 = preprocess_gloss(train_df_3)\n",
    "\n",
    "# with open(\"gloss_sentences_train1.json\", \"w\") as file:\n",
    "#     json.dump(gloss_sentences_train_1, file, indent=4)\n",
    "\n",
    "# with open(\"gloss_sentences_train2.json\", \"w\") as file:\n",
    "#     json.dump(gloss_sentences_train_2, file, indent=4)\n",
    "\n",
    "# with open(\"gloss_sentences_train3.json\", \"w\") as file:\n",
    "#     json.dump(gloss_sentences_train_3, file, indent=4)\n",
    "\n",
    "# with open('gloss_sentences_train1.json', 'r') as f:\n",
    "#     data1 = json.load(f)\n",
    "\n",
    "# with open('gloss_sentences_train2.json', 'r') as f:\n",
    "#     data2 = json.load(f)\n",
    "\n",
    "# with open('gloss_sentences_train3.json', 'r') as f:\n",
    "#     data3 = json.load(f)\n",
    "\n",
    "# train_data = {**data1, **data2, **data3}\n",
    "\n",
    "# with open('gloss_sentences_train.json', 'w') as file:\n",
    "#     json.dump(train_data, file, indent=4)\n",
    "\n",
    "# gloss_sentences_dev = preprocess_gloss(dev_df)\n",
    "\n",
    "# with open(\"gloss_sentences_dev.json\", \"w\") as file:\n",
    "#     json.dump(gloss_sentences_dev, file, indent=4)\n",
    "\n",
    "# gloss_sentences_test = preprocess_gloss(test_df)\n",
    "\n",
    "# with open(\"gloss_sentences_test.json\", \"w\") as file:\n",
    "#     json.dump(gloss_sentences_test, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8f95d-a9eb-4611-bb96-95660cf4fabe",
   "metadata": {},
   "source": [
    "### Opening the files that have stored the gloss sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763f2815-13ed-4cbf-8c10-5992ecefb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"gloss_sentences_train.json\", \"r\") as file:\n",
    "    gloss_cache_train = json.load(file)\n",
    "\n",
    "with open(\"gloss_sentences_dev.json\", \"r\") as file:\n",
    "    gloss_cache_dev = json.load(file)\n",
    "\n",
    "with open(\"gloss_sentences_test.json\", \"r\") as file:\n",
    "    gloss_cache_test = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30003d7-3d23-40e5-ad90-905f682b5bb4",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d497cb9c-c20e-42d5-ab08-dce20c6536b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, gloss_cache = None):\n",
    "        self.anchor_positive_negative_triplets = []\n",
    "        self.gloss_cache = gloss_cache\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            expected_order = ast.literal_eval(row[\"expected_order\"])\n",
    "            for i in range(1, 5):\n",
    "                if self.gloss_cache is not None:\n",
    "                    sentence = gloss_cache[row[\"sentence\"]]\n",
    "                else:\n",
    "                    sentence = row[\"sentence\"]\n",
    "                self.anchor_positive_negative_triplets.append((\n",
    "                    sentence,\n",
    "                    os.path.join(\"train\", row[\"compound\"].replace(\"'s\", \"_s\"), expected_order[0]),\n",
    "                    os.path.join(\"train\", row[\"compound\"].replace(\"'s\", \"_s\"), expected_order[i])\n",
    "                ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_positive_negative_triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_text, pos_img_path, neg_img_path = self.anchor_positive_negative_triplets[idx]\n",
    "        pos_img = Image.open(pos_img_path).convert('RGB')\n",
    "        neg_img = Image.open(neg_img_path).convert('RGB')\n",
    "        return (anchor_text, pos_img, neg_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e0f5a-3c32-4d2d-8cb8-f9d5c722389a",
   "metadata": {},
   "source": [
    "### Triplet Loss function using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e3033f-f8d2-46c8-86f9-393bc67a3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_cosine_similarity(anchor_embedding, positive_embedding, negative_embedding, margin=0.3):\n",
    "    pos_sim = torch.nn.functional.cosine_similarity(anchor_embedding, positive_embedding)\n",
    "    neg_sim = torch.nn.functional.cosine_similarity(anchor_embedding, negative_embedding)\n",
    "    loss = torch.relu(margin + neg_sim - pos_sim).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0b423-b002-4bbc-92c3-c73c0071957e",
   "metadata": {},
   "source": [
    "### Triplet Loss function using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c691da-4b01-43ba-b0ec-7e1b64bdbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_euclidean_distance(anchor_embedding, positive_embedding, negative_embedding, margin=0.3):\n",
    "    pos_dist = torch.nn.functional.pairwise_distance(anchor_embedding, positive_embedding, p=2)\n",
    "    neg_dist = torch.nn.functional.pairwise_distance(anchor_embedding, negative_embedding, p=2)\n",
    "    loss = torch.relu(pos_dist - neg_dist + margin).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2a8e5-2000-4a9c-9586-8ec37c81a2d7",
   "metadata": {},
   "source": [
    "### Function to use the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0e1626-9fbb-44d3-9f86-874179b48970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate_fn(batch):\n",
    "    texts = [item[0] for item in batch]\n",
    "    pos_images = [item[1] for item in batch]\n",
    "    neg_images = [item[2] for item in batch]\n",
    "\n",
    "    inputs_pos = processor(text=texts, images=pos_images, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs_neg = processor(text=texts, images=neg_images, return_tensors='pt', padding=True, truncation=True)\n",
    "    return inputs_pos, inputs_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb2c80-6add-443f-a31e-721e295547be",
   "metadata": {},
   "source": [
    "### Function to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9125aef3-d7c3-49a1-bac2-86e9622a93cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, dataset, use_cosine=True, patience=3, max_epochs=25, model_name=\"model\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=train_collate_fn)\n",
    "\n",
    "    best_dev_ndcg = 0\n",
    "    patience_counter = 0\n",
    "    best_path = f\"{model_name}_best.pt\"\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch + 1}\", leave=False)\n",
    "\n",
    "        for inputs_pos, inputs_neg in pbar:\n",
    "            outputs_pos = model(**inputs_pos)\n",
    "            outputs_neg = model(**inputs_neg)\n",
    "\n",
    "            anchor_emb = outputs_pos.text_embeds\n",
    "            pos_emb = outputs_pos.image_embeds\n",
    "            neg_emb = outputs_neg.image_embeds\n",
    "\n",
    "            if use_cosine:\n",
    "                loss = triplet_loss_cosine_similarity(anchor_emb, pos_emb, neg_emb)\n",
    "            else:\n",
    "                loss = triplet_loss_euclidean_distance(anchor_emb, pos_emb, neg_emb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        train_ndcg = calculate_ndcg_score(train_df, \"train\", model, use_cosine, gloss_cache_train)\n",
    "        dev_ndcg = calculate_ndcg_score(dev_df, \"dev\", model, use_cosine, gloss_cache_dev)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - Avg Loss: {avg_loss:.4f} - Train NDCG: {train_ndcg:.4f} - Dev NDCG: {dev_ndcg:.4f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if dev_ndcg > best_dev_ndcg:\n",
    "            best_dev_ndcg = dev_ndcg\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in {patience} epochs)\")\n",
    "                break\n",
    "\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d698c3-ed0b-43ee-9839-aadab62e34a7",
   "metadata": {},
   "source": [
    "### Functions to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59295753-ca66-41ec-9cd2-7efc86a5543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(relevances):\n",
    "    relevances = np.asfarray(relevances)\n",
    "    score = relevances[0]\n",
    "    for i in range(1, len(relevances)):\n",
    "        score += relevances[i] / np.log2(i + 2)\n",
    "    return score\n",
    "\n",
    "def ndcg_score(ideal_ranking, predicted_ranking):\n",
    "    image_to_relevance_score = {}\n",
    "    \n",
    "    for i in range(0, len(ideal_ranking)):\n",
    "        image_to_relevance_score[ideal_ranking[i]] = len(ideal_ranking) - i \n",
    "\n",
    "    predicted_relevance = []\n",
    "    ideal_relevance = []\n",
    "    \n",
    "    for index in range(0, len(ideal_ranking)):\n",
    "        ideal_relevance.append(image_to_relevance_score[ideal_ranking[index]])\n",
    "        predicted_relevance.append(image_to_relevance_score[predicted_ranking[index]])\n",
    "\n",
    "    dcg_val = dcg(predicted_relevance)\n",
    "    idcg_val = dcg(ideal_relevance)\n",
    "\n",
    "    return dcg_val / idcg_val\n",
    "\n",
    "def get_predicted_ranking_cosine(model, image2image_paths, text):\n",
    "    predicted_ranking = []\n",
    "\n",
    "    for image_name, image_path in image2image_paths.items():\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(text=text, images=img, return_tensors='pt', padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        predicted_ranking.append((image_name, \n",
    "                                  torch.nn.functional.cosine_similarity(outputs.text_embeds, \n",
    "                                                                        outputs.image_embeds).squeeze()))\n",
    "\n",
    "    predicted_ranking = reversed(sorted(predicted_ranking, key=lambda x:x[1]))\n",
    "    predicted_ranking = [x[0] for x in predicted_ranking]\n",
    "    \n",
    "    return predicted_ranking\n",
    "\n",
    "def get_predicted_ranking_euclidean(model, image2image_paths, text):\n",
    "    predicted_ranking = []\n",
    "\n",
    "    for image_name, image_path in image2image_paths.items():\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(text=text, images=img, return_tensors='pt', padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        predicted_ranking.append((image_name, \n",
    "                                  torch.nn.functional.pairwise_distance(outputs.text_embeds, \n",
    "                                                                                   outputs.image_embeds,\n",
    "                                                                                   p=2).squeeze()))\n",
    "    predicted_ranking = sorted(predicted_ranking, key=lambda x:x[1])\n",
    "    predicted_ranking = [x[0] for x in predicted_ranking]\n",
    "    \n",
    "    return predicted_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71d03d-0a29-4e93-8afe-cc32d70d7928",
   "metadata": {},
   "source": [
    "### Function to calculate NDCG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d8a87d-7ff8-400c-bf3d-eb02d5a438bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_score(df, df_type, model, use_cosine = True, gloss_cache = None):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    for index, row in df.iterrows():\n",
    "        ideal_ranking = ast.literal_eval(row[\"expected_order\"])\n",
    "\n",
    "        if gloss_cache is None:\n",
    "            text = row[\"sentence\"]\n",
    "        else:\n",
    "            text = gloss_cache[row[\"sentence\"]]\n",
    "        image_to_image_paths = {}\n",
    "\n",
    "        for image_name in ideal_ranking:\n",
    "            image_to_image_paths[image_name] = os.path.join(df_type, \n",
    "                                                            row[\"compound\"].replace(\"'s\", \"_s\"), \n",
    "                                                            image_name)\n",
    "\n",
    "        if use_cosine:\n",
    "            predicted_ranking = get_predicted_ranking_cosine(model, image_to_image_paths, text)\n",
    "        else:\n",
    "            predicted_ranking = get_predicted_ranking_euclidean(model, image_to_image_paths, text)\n",
    "            \n",
    "\n",
    "        score = ndcg_score(ideal_ranking, predicted_ranking)\n",
    "        scores.append(score)\n",
    "\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d35d8-ed10-417b-b0f5-dac5ecb196e8",
   "metadata": {},
   "source": [
    "### Function to 1pc Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9ffb48-3b21-4577-b6be-43865fe3a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_1pc_accuracy(df, df_type, model, use_cosine = True, gloss_cache = None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        ideal_ranking = ast.literal_eval(row[\"expected_order\"])\n",
    "\n",
    "        if gloss_cache is not None:\n",
    "            text = gloss_cache[row[\"sentence\"]]\n",
    "        else:\n",
    "            text = row[\"sentence\"]\n",
    "        image2image_paths = {}\n",
    "\n",
    "        for image_name in ideal_ranking:\n",
    "            image2image_paths[image_name] = os.path.join(df_type, \n",
    "                                                            row[\"compound\"].replace(\"'s\", \"_s\"), \n",
    "                                                            image_name)\n",
    "\n",
    "        if use_cosine:\n",
    "            predicted_ranking = get_predicted_ranking_cosine(model, image2image_paths, text)\n",
    "        else:\n",
    "            predicted_ranking = get_predicted_ranking_euclidean(model, image2image_paths, text)\n",
    "\n",
    "        if ideal_ranking[0] == predicted_ranking[0]:\n",
    "            correct += 1\n",
    "\n",
    "    return round(correct / len(df), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82ce18-c010-40ed-9372-7112c017476f",
   "metadata": {},
   "source": [
    "### Train model with rank 8 and triplet loss using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e23aaba-40e4-4f03-af06-edec6cd69be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 0.2628 - Train NDCG: 0.9478 - Dev NDCG: 0.9199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.2435 - Train NDCG: 0.9661 - Dev NDCG: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.2094 - Train NDCG: 0.9733 - Dev NDCG: 0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.1460 - Train NDCG: 0.9766 - Dev NDCG: 0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 0.0773 - Train NDCG: 0.9798 - Dev NDCG: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Avg Loss: 0.0364 - Train NDCG: 0.9789 - Dev NDCG: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Avg Loss: 0.0152 - Train NDCG: 0.9780 - Dev NDCG: 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Avg Loss: 0.0068 - Train NDCG: 0.9757 - Dev NDCG: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Avg Loss: 0.0030 - Train NDCG: 0.9774 - Dev NDCG: 0.9213\n",
      "Early stopping at epoch 9 (no improvement in 3 epochs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rank8_cosine_best.pt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 8\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model1 = get_peft_model(model, lora_config)\n",
    "train(model1, train_dataset,model_name=\"rank8_cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6745a7ce-1c54-44db-9008-dc92f194de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev 1pc Accuracy: 67.0\n"
     ]
    }
   ],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model1, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e1c27d6-d348-4fef-98b9-59c8e023966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1pc Accuracy: 27.0\n"
     ]
    }
   ],
   "source": [
    "acc = calculate_1pc_accuracy(test_df, \"test\", model1, gloss_cache = gloss_cache_test)\n",
    "print(f\"Test 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40ed52-8159-4139-b0e3-457da4a7617a",
   "metadata": {},
   "source": [
    "### Train model with rank 8 and triplet loss using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "9a0b166d-c282-4ef6-8a38-9f4f6b3b432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 0.2720 - Train NDCG: 0.9400 - Dev NDCG: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.2546 - Train NDCG: 0.9559 - Dev NDCG: 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.2279 - Train NDCG: 0.9724 - Dev NDCG: 0.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.1804 - Train NDCG: 0.9765 - Dev NDCG: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 0.1159 - Train NDCG: 0.9818 - Dev NDCG: 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Avg Loss: 0.0578 - Train NDCG: 0.9785 - Dev NDCG: 0.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Avg Loss: 0.0250 - Train NDCG: 0.9781 - Dev NDCG: 0.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Avg Loss: 0.0091 - Train NDCG: 0.9775 - Dev NDCG: 0.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Avg Loss: 0.0043 - Train NDCG: 0.9768 - Dev NDCG: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Avg Loss: 0.0024 - Train NDCG: 0.9738 - Dev NDCG: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Avg Loss: 0.0017 - Train NDCG: 0.9778 - Dev NDCG: 0.9517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Avg Loss: 0.0012 - Train NDCG: 0.9761 - Dev NDCG: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Avg Loss: 0.0010 - Train NDCG: 0.9766 - Dev NDCG: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Avg Loss: 0.0010 - Train NDCG: 0.9769 - Dev NDCG: 0.9463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Avg Loss: 0.0010 - Train NDCG: 0.9771 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Avg Loss: 0.0021 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Avg Loss: 0.0010 - Train NDCG: 0.9770 - Dev NDCG: 0.9459\n"
     ]
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 8\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model2 = get_peft_model(model, lora_config)\n",
    "train(model2, train_dataset, use_cosine = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "382132df-8ca3-4f1d-a348-667a50a7f2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev 1pc Accuracy: 67.0\n"
     ]
    }
   ],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model2, use_cosine = False, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861dadb-cf48-4c3a-8ca0-140831492d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b65437-bbd8-4831-8850-669ebcbe3408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227974fa-6c1d-4bc4-a019-c733fcdb3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(test_df, \"test\", model2, use_cosine = False, gloss_cache = gloss_cache_test)\n",
    "print(f\"Test 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee647d-90be-4318-97f2-70ec460d0991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d39d77-62e0-4e84-936a-ee0c27d061da",
   "metadata": {},
   "source": [
    "### Train model with rank 4 and triplet loss using cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448d9c0-9bba-47c9-b20d-585a2461b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 4\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model3 = get_peft_model(model, lora_config)\n",
    "train(model3, train_dataset, use_cosine = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8537d-4604-4eb7-917c-5b09f6e4b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model3, use_cosine = False, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58219d6-e628-4489-a252-65db0d2285ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(test_df, \"test\", model3, use_cosine = False, gloss_cache = gloss_cache_test)\n",
    "print(f\"Test 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d677d-d69f-4296-b99d-b9aaa91962cd",
   "metadata": {},
   "source": [
    "### Train model with rank 4 and triplet loss using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b0de3-14dd-4337-b911-03dc3bd2083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 4\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model4 = get_peft_model(model, lora_config)\n",
    "train(model4, train_dataset, use_cosine = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d88f01-eaa5-485a-9e70-9e1c939900b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model4, use_cosine = False, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a85c7-17c9-4c0e-b8fb-8f26e95ce56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(test_df, \"test\", model4, use_cosine = False, gloss_cache = gloss_cache_test)\n",
    "print(f\"Test 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90ec4d-5ff2-4455-9fd0-96a84c77f51b",
   "metadata": {},
   "source": [
    "### Train model with rank 2 and triplet loss using cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0efb5b-0bc3-41e2-9af5-0f09d3fd1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 16\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model5 = get_peft_model(model, lora_config)\n",
    "train(model5, train_dataset, use_cosine = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b5927-d258-42ad-b905-f2b54f6048e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9502e-8839-485e-99b2-6400d70e436d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9619e0a-1480-4b27-b40a-98c03fda6f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07035b-302b-450a-b67e-605fa858ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d257c-7be5-4567-85ad-5d7cf5cef17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbeb11-6805-4019-8820-307623b59b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ab18e-f496-496f-b02e-0cbb5621c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model5, use_cosine = False, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293a364-ad20-4f4d-b7c8-bdbd884c4890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498dc84-52c6-42dc-befb-1d7f1620c473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc18180-e148-41e0-bdae-32f0454f7ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1badde-316d-4885-ac10-395d095c4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff6e2c0-b782-4e6a-85b9-d0fb7f48cad0",
   "metadata": {},
   "source": [
    "### Train model with rank 2 and triplet loss using Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e161b1-7fbc-4ba9-8d37-86a8150c5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "rank = 16\n",
    "lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=2*rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "train_dataset = TripletDataset(train_df, gloss_cache_train)\n",
    "model6 = get_peft_model(model, lora_config)\n",
    "train(model6, train_dataset, use_cosine = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977358fd-0c10-46dc-8fdb-fbd63de7fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(dev_df, \"dev\", model6, use_cosine = False, gloss_cache = gloss_cache_dev)\n",
    "print(f\"Dev 1pc Accuracy: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac22087-a5fb-4f2b-8332-b114fb3d22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_1pc_accuracy(test_df, \"test\", model6, use_cosine = False, gloss_cache = gloss_cache_test)\n",
    "print(f\"Test 1pc Accuracy: {acc*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
